{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nf24wsMsIsOE"
   },
   "outputs": [],
   "source": [
    "################# Code for loading the Human Scans & Data Augmentation##############################\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "def load_images(input_folder, desired_height, desired_width):\n",
    "    input_images = []\n",
    "    loaded_indices = []\n",
    "\n",
    "    file_pattern = re.compile(r\"(circum|radial|longit)_(\\d+)\\.png\")\n",
    "\n",
    "    image_paths = {}\n",
    "\n",
    "    for file in os.listdir(input_folder):\n",
    "        match = file_pattern.match(file)\n",
    "        if match:\n",
    "            category, index = match.groups()\n",
    "            index = int(index)\n",
    "\n",
    "            if index not in image_paths:\n",
    "                image_paths[index] = {}\n",
    "\n",
    "            image_paths[index][category] = os.path.join(input_folder, file)\n",
    "\n",
    "    for index in sorted(image_paths.keys()):\n",
    "        paths = image_paths[index]\n",
    "        if all(category in paths for category in [\"circum\", \"radial\", \"longit\"]):\n",
    "            images = [Image.open(paths[category]).convert(\"L\").resize((desired_width, desired_height))\n",
    "                      for category in [\"circum\", \"radial\", \"longit\"]]\n",
    "\n",
    "            combined_image = np.stack(images, axis=-1)\n",
    "            input_images.append(combined_image)\n",
    "            loaded_indices.append(index)  # Save the index\n",
    "\n",
    "    return np.array(input_images), loaded_indices\n",
    "\n",
    "# Load images and get their indices\n",
    "input_folder = '/Human_CMR/'  # locate data folder for inputs\n",
    "desired_height = 128\n",
    "desired_width = 128\n",
    "\n",
    "input_images, indices = load_images(input_folder, desired_height, desired_width)\n",
    "\n",
    "\n",
    "print(f\"Loaded {input_images.shape[0]} sets of images.\")\n",
    "print(f\"Indices of loaded images: {indices}\")\n",
    "\n",
    "output_folder = '/Human_CMR/'  # locate data folder for outputs\n",
    "output_images = []\n",
    "\n",
    "# Resize each image to 128x128, add a channel dimension, and display it\n",
    "for i in indices:\n",
    "    output_paths = [output_folder + f\"patient_{i}_LGE.png\"]\n",
    "    images = []\n",
    "\n",
    "    for path in output_paths:\n",
    "        img = Image.open(path).convert(\"L\").resize((128, 128))  # Resize to 128x128\n",
    "        img_array = np.array(img)[..., np.newaxis]  # Add channel dimension (H, W) -> (H, W, 1)\n",
    "        images.append(img_array)\n",
    "\n",
    "    output_images.extend(images)  # Append images to the output list\n",
    "\n",
    "# Convert the list to a NumPy array with shape (5, 128, 128, 1)\n",
    "output_images = np.array(output_images)\n",
    "\n",
    "\n",
    "threshold_value = 100\n",
    "output_images[output_images <= threshold_value] = 0\n",
    "output_images[output_images > threshold_value] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVLwyQVoOO16"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Lambda, Conv2D, BatchNormalization, Dropout, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "seed = 42\n",
    "np.random.seed = seed\n",
    "\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "# Define the Dice coefficient metric function (just for training evaluation)\n",
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "\n",
    "\n",
    "#Build the UNet model\n",
    "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "#Contraction path\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "#Expansive path\n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "\n",
    "# Compile the model with masked losses and metrics\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coefficient])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5lTFy9uDPlP"
   },
   "outputs": [],
   "source": [
    "model.load_weights('UNet_single_fidelity_random_1.h5')\n",
    "preds_test = model.predict(input_images, verbose=1)\n",
    "preds_test_t = (preds_test > 0.75).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZ6sailkKHuo"
   },
   "outputs": [],
   "source": [
    "# Define the circular mask function\n",
    "def create_circular_mask(height, width, radius=63):\n",
    "    center = (int(height / 2), int(width / 2))\n",
    "    Y, X = np.ogrid[:height, :width]\n",
    "    dist_from_center = np.sqrt((X - center[1]) ** 2 + (Y - center[0]) ** 2)\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask.astype(np.float32)\n",
    "\n",
    "# Generate the circular mask for 128x128 images\n",
    "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
    "circular_mask = create_circular_mask(IMG_HEIGHT, IMG_WIDTH)\n",
    "circular_mask = tf.convert_to_tensor(circular_mask, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrDXAhnCKOnu"
   },
   "outputs": [],
   "source": [
    "# y_test_sample = output_images[i, :, :, 0]\n",
    "# thresholded_y_test = tf.cast(y_test_sample > 0, tf.float32)\n",
    "# masked_y_test = thresholded_y_test * circular_mask\n",
    "\n",
    "i=4\n",
    "# Mask and threshold the prediction\n",
    "y_pred_sample = preds_test_t[i, :, :, 0]\n",
    "thresholded_y_pred = tf.cast(y_pred_sample > 0, tf.float32)\n",
    "masked_y_pred = thresholded_y_pred * circular_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YzP-W27-FIAf"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define functions for calculating metrics\n",
    "def dice_score(masked_y_true, masked_y_pred, smooth=1e-6):\n",
    "    intersection = tf.reduce_sum(masked_y_true * masked_y_pred)\n",
    "    union = tf.reduce_sum(masked_y_true) + tf.reduce_sum(masked_y_pred)\n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "\n",
    "def accuracy(masked_y_true, masked_y_pred, circular_mask):\n",
    "    correct = tf.reduce_sum(tf.cast(masked_y_true == masked_y_pred, tf.float32) * circular_mask)\n",
    "    total = tf.reduce_sum(circular_mask)\n",
    "    return correct / total\n",
    "\n",
    "def precision(masked_y_true, masked_y_pred, smooth=1e-6):\n",
    "    true_positives = tf.reduce_sum(masked_y_true * masked_y_pred)\n",
    "    predicted_positives = tf.reduce_sum(masked_y_pred)\n",
    "    return (true_positives + smooth) / (predicted_positives + smooth)\n",
    "\n",
    "def recall(masked_y_true, masked_y_pred, smooth=1e-6):\n",
    "    true_positives = tf.reduce_sum(masked_y_true * masked_y_pred)\n",
    "    actual_positives = tf.reduce_sum(masked_y_true)\n",
    "    return (true_positives + smooth) / (actual_positives + smooth)\n",
    "\n",
    "def iou(masked_y_true, masked_y_pred, smooth=1e-6):\n",
    "    intersection = tf.reduce_sum(masked_y_true * masked_y_pred)\n",
    "    union = tf.reduce_sum(masked_y_true) + tf.reduce_sum(masked_y_pred) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "# Calculate and print metrics for each test sample\n",
    "metrics_results = {\n",
    "    'dice_infarct': [],\n",
    "    'accuracy_infarct': [],\n",
    "    'precision_infarct': [],\n",
    "    'recall_infarct': [],\n",
    "    'iou_infarct': [],\n",
    "\n",
    "}\n",
    "\n",
    "for i in range(len(output_images)):\n",
    "    # Mask and threshold the ground truth\n",
    "    y_test_sample = output_images[i, :, :, 0]\n",
    "    thresholded_y_test = tf.cast(y_test_sample > 0, tf.float32)\n",
    "    masked_y_test = thresholded_y_test * circular_mask\n",
    "\n",
    "    # Mask and threshold the prediction\n",
    "    y_pred_sample = preds_test_t[i, :, :, 0]\n",
    "    thresholded_y_pred = tf.cast(y_pred_sample > 0, tf.float32)\n",
    "    masked_y_pred = thresholded_y_pred * circular_mask\n",
    "\n",
    "    # Calculate metrics for infarct region\n",
    "    dice_infarct = dice_score(masked_y_test, masked_y_pred)\n",
    "    acc_infarct = accuracy(masked_y_test, masked_y_pred, circular_mask).numpy()\n",
    "    prec_infarct = precision(masked_y_test, masked_y_pred).numpy()\n",
    "    rec_infarct = recall(masked_y_test, masked_y_pred).numpy()\n",
    "    iou_infarct = iou(masked_y_test, masked_y_pred).numpy()\n",
    "\n",
    "    metrics_results['dice_infarct'].append(dice_infarct.numpy())\n",
    "    metrics_results['accuracy_infarct'].append(acc_infarct)\n",
    "    metrics_results['precision_infarct'].append(prec_infarct)\n",
    "    metrics_results['recall_infarct'].append(rec_infarct)\n",
    "    metrics_results['iou_infarct'].append(iou_infarct)\n",
    "\n",
    "\n",
    "    # Print metrics for each sample\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\" - Dice Score (Infarct): {dice_infarct.numpy()}\")\n",
    "    print(f\" - Accuracy (Infarct): {acc_infarct}\")\n",
    "    print(f\" - Precision (Infarct): {prec_infarct}\")\n",
    "    print(f\" - Recall (Infarct): {rec_infarct}\")\n",
    "    print(f\" - IoU (Infarct): {iou_infarct}\")\n",
    "\n",
    "# Calculate average metrics across all test samples\n",
    "average_metrics = {metric: np.mean(scores) for metric, scores in metrics_results.items()}\n",
    "print(\"\\nAverage Metrics Across All Test Samples:\")\n",
    "for metric, avg_score in average_metrics.items():\n",
    "    print(f\" - {metric.capitalize()}: {avg_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lr2sbVdxFH6z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
